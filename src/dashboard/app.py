"""Streamlit –¥–∞—à–±–æ—Ä–¥ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å ML API."""

from typing import Dict

import pandas as pd
import requests
import streamlit as st

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è API
API_BASE_URL = "http://localhost:8000"

st.set_page_config(
    page_title="ML API Dashboard", page_icon="ü§ñ", layout="wide", initial_sidebar_state="expanded"
)


# –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–º –≤ session state
if "access_token" not in st.session_state:
    st.session_state.access_token = None
if "username" not in st.session_state:
    st.session_state.username = None


def get_headers():
    """–ü–æ–ª—É—á–∏—Ç—å headers —Å —Ç–æ–∫–µ–Ω–æ–º."""
    if st.session_state.access_token:
        return {"Authorization": f"Bearer {st.session_state.access_token}"}
    return {}


def login_user(username: str, password: str):
    """–í–æ–π—Ç–∏ –≤ —Å–∏—Å—Ç–µ–º—É."""
    try:
        response = requests.post(
            f"{API_BASE_URL}/auth/login",
            data={"username": username, "password": password},
        )
        response.raise_for_status()
        data = response.json()
        st.session_state.access_token = data["access_token"]
        st.session_state.username = username
        return True, "–£—Å–ø–µ—à–Ω—ã–π –≤—Ö–æ–¥!"
    except Exception as e:
        return False, f"–û—à–∏–±–∫–∞ –≤—Ö–æ–¥–∞: {e}"


def logout_user():
    """–í—ã–π—Ç–∏ –∏–∑ —Å–∏—Å—Ç–µ–º—ã."""
    st.session_state.access_token = None
    st.session_state.username = None


def register_user(username: str, password: str):
    """–ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    try:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º email –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        email = f"{username}@mlapi.local"

        response = requests.post(
            f"{API_BASE_URL}/auth/register",
            json={"username": username, "email": email, "password": password},
        )
        response.raise_for_status()
        return True, "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞! –¢–µ–ø–µ—Ä—å –º–æ–∂–µ—Ç–µ –≤–æ–π—Ç–∏."
    except Exception as e:
        return False, f"–û—à–∏–±–∫–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏: {e}"


# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å API
def get_available_models():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–∏–ø–æ–≤ –º–æ–¥–µ–ª–µ–π."""
    try:
        response = requests.get(f"{API_BASE_URL}/models", headers=get_headers())
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
        return []


def get_trained_models():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π."""
    try:
        response = requests.get(f"{API_BASE_URL}/models/trained", headers=get_headers())
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: {e}")
        return []


def train_model(model_type: str, model_name: str, hyperparameters: Dict, features, labels):
    """–û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å."""
    try:
        payload = {
            "model_type": model_type,
            "model_name": model_name,
            "hyperparameters": hyperparameters,
            "train_data": {"features": features, "labels": labels},
        }

        response = requests.post(f"{API_BASE_URL}/models/train", json=payload, headers=get_headers())
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
        return None


def predict(model_id: str, features):
    """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ."""
    try:
        payload = {"features": features}
        response = requests.post(
            f"{API_BASE_URL}/models/{model_id}/predict", json=payload, headers=get_headers()
        )
        response.raise_for_status()
        return response.json()
    except requests.exceptions.HTTPError as e:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –æ—à–∏–±–∫—É –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞
        try:
            error_detail = e.response.json().get("detail", str(e))
            st.error(f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {error_detail}")
        except Exception:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        return None
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        return None


def predict_csv_from_dataset(model_id: str, dataset_id: str, csv_file):
    """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏–∑ CSV —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
    try:
        files = {'file': ('data.csv', csv_file, 'text/csv')}
        data = {'dataset_id': dataset_id}

        response = requests.post(
            f"{API_BASE_URL}/models/{model_id}/predict-csv",
            files=files,
            data=data,
            headers=get_headers()
        )
        response.raise_for_status()
        return response.json()
    except requests.exceptions.HTTPError as e:
        try:
            error_detail = e.response.json().get("detail", str(e))
            st.error(f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {error_detail}")
        except Exception:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        return None
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        return None


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def has_feature_encoders(dataset_id: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –µ—Å—Ç—å –ª–∏ —É –¥–∞—Ç–∞—Å–µ—Ç–∞ —ç–Ω–∫–æ–¥–µ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–Ω–µ —Ç–æ–ª—å–∫–æ —Ç–∞—Ä–≥–µ—Ç–∞)."""
    from pathlib import Path

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞–ø–∫–∏ —Å —ç–Ω–∫–æ–¥–µ—Ä–∞–º–∏
    encoders_dir = Path("datasets") / f"{dataset_id}_encoders"

    if not encoders_dir.exists():
        return False

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —ç–Ω–∫–æ–¥–µ—Ä (–Ω–µ —Å—á–∏—Ç–∞—è target_encoder)
    encoder_files = list(encoders_dir.glob("*.json"))

    # –£ iris —Ç–æ–ª—å–∫–æ target_encoder, —É adult - –º–Ω–æ–≥–æ —ç–Ω–∫–æ–¥–µ—Ä–æ–≤ –¥–ª—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    return len(encoder_files) > 0


def delete_model(model_id: str):
    """–£–¥–∞–ª–∏—Ç—å –º–æ–¥–µ–ª—å."""
    try:
        response = requests.delete(f"{API_BASE_URL}/models/{model_id}", headers=get_headers())
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
        return None


def delete_dataset(dataset_id: str):
    """–£–¥–∞–ª–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç."""
    try:
        response = requests.delete(f"{API_BASE_URL}/datasets/{dataset_id}", headers=get_headers())
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞: {e}")
        return None


def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å API."""
    try:
        response = requests.get(f"{API_BASE_URL}/health")
        response.raise_for_status()
        return response.json()
    except Exception as e:
        return {"status": "unavailable", "error": str(e)}


def upload_dataset(file, target_column: str, dataset_name: str = None, preprocess_categorical: bool = True, make_shared: bool = False):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç."""
    try:
        files = {"file": (file.name, file, "text/csv")}
        data = {
            "target_column": target_column,
            "preprocess_categorical": str(preprocess_categorical).lower(),
            "make_shared": str(make_shared).lower()
        }
        if dataset_name:
            data["dataset_name"] = dataset_name

        response = requests.post(
            f"{API_BASE_URL}/datasets/upload",
            headers=get_headers(),
            files=files,
            data=data
        )
        response.raise_for_status()
        return response.json()
    except requests.exceptions.HTTPError as e:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –∏–∑ –æ—Ç–≤–µ—Ç–∞ API
        try:
            error_detail = e.response.json().get("detail", str(e))
        except Exception:
            error_detail = str(e)
        st.error(f"‚ùå {error_detail}")
        return None
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞—Ç–∞—Å–µ—Ç–∞: {e}")
        return None


def get_datasets():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤."""
    try:
        response = requests.get(f"{API_BASE_URL}/datasets", headers=get_headers())
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤: {e}")
        return []


def get_dataset_info(dataset_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞—Ç–∞—Å–µ—Ç–µ."""
    try:
        response = requests.get(f"{API_BASE_URL}/datasets/{dataset_id}", headers=get_headers())
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∞—Ç–∞—Å–µ—Ç–µ: {e}")
        return None


def train_model_from_dataset(model_type: str, model_name: str, dataset_id: str, hyperparameters: Dict):
    """–û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ."""
    try:
        payload = {
            "model_type": model_type,
            "model_name": model_name,
            "dataset_id": dataset_id,
            "hyperparameters": hyperparameters,
        }
        response = requests.post(
            f"{API_BASE_URL}/models/train-from-dataset",
            json=payload,
            headers=get_headers()
        )
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ: {e}")
        return None


# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
if not st.session_state.access_token:
    st.title("üîê –í—Ö–æ–¥ –≤ —Å–∏—Å—Ç–µ–º—É")

    tab1, tab2 = st.tabs(["–í—Ö–æ–¥", "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è"])

    with tab1:
        st.header("–í–æ–π—Ç–∏")

        with st.form("login_form"):
            username = st.text_input("–ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
            password = st.text_input("–ü–∞—Ä–æ–ª—å", type="password")
            submit = st.form_submit_button("–í–æ–π—Ç–∏")

            if submit:
                if username and password:
                    success, message = login_user(username, password)
                    if success:
                        st.success(message)
                        st.rerun()
                    else:
                        st.error(message)
                else:
                    st.error("–í–≤–µ–¥–∏—Ç–µ –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –ø–∞—Ä–æ–ª—å")

        st.info("**–¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:**\n- admin / admin")

    with tab2:
        st.header("–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è")

        with st.form("register_form"):
            new_username = st.text_input("–ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è", key="reg_username")
            new_password = st.text_input("–ü–∞—Ä–æ–ª—å", type="password", key="reg_password")
            new_password_confirm = st.text_input("–ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å", type="password", key="reg_password_confirm")
            register_submit = st.form_submit_button("–ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è")

            if register_submit:
                if new_username and new_password and new_password_confirm:
                    if new_password != new_password_confirm:
                        st.error("–ü–∞—Ä–æ–ª–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç")
                    elif len(new_password) < 6:
                        st.error("–ü–∞—Ä–æ–ª—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ –º–µ–Ω–µ–µ 6 —Å–∏–º–≤–æ–ª–æ–≤")
                    else:
                        success, message = register_user(new_username, new_password)
                        if success:
                            st.success(message)
                        else:
                            st.error(message)
                else:
                    st.error("–ó–∞–ø–æ–ª–Ω–∏—Ç–µ –≤—Å–µ –ø–æ–ª—è")

    st.stop()


# –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å (–ø–æ—Å–ª–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏)
st.title("ü§ñ ML API Service Dashboard")
st.markdown(f"–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å, **{st.session_state.username}**!")

# Sidebar - –°—Ç–∞—Ç—É—Å API
with st.sidebar:
    st.header("üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å")
    st.write(f"**{st.session_state.username}**")

    if st.button("üö™ –í—ã–π—Ç–∏"):
        logout_user()
        st.rerun()

    st.divider()

    st.header("üìä –°—Ç–∞—Ç—É—Å API")

    if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å"):
        st.rerun()

    health = health_check()

    if health.get("status") == "healthy":
        st.success("‚úÖ API —Ä–∞–±–æ—Ç–∞–µ—Ç")
        st.metric("–í–µ—Ä—Å–∏—è", health.get("version", "N/A"))
        st.metric("–û–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", health.get("models_count", 0))
    else:
        st.error("‚ùå API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        st.write(health.get("error", ""))

    st.divider()

    st.header("üìö –ù–∞–≤–∏–≥–∞—Ü–∏—è")
    page = st.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
        ["üìÅ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏", "üéØ –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å", "üîÆ –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ", "üìã –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏"],
    )


# –û—Å–Ω–æ–≤–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
if page == "üìÅ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏":
    st.header("üìÅ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏")

    tab1, tab2 = st.tabs(["–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç", "–ú–æ–∏ –¥–∞—Ç–∞—Å–µ—Ç—ã"])

    with tab1:
        st.subheader("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞")

        upload_method = st.radio(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏:",
            ["üìÇ –í—ã–±—Ä–∞—Ç—å –≥–æ—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç", "üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–æ–π CSV"],
            help="–í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–∏–Ω –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Å–≤–æ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π"
        )

        if upload_method == "üìÇ –í—ã–±—Ä–∞—Ç—å –≥–æ—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç":
            st.write("**–î–æ—Å—Ç—É–ø–Ω—ã–µ –≥–æ—Ç–æ–≤—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã:**")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤
            import os
            test_data_path = "test_data"
            available_datasets = {}

            if os.path.exists(os.path.join(test_data_path, "iris.csv")):
                available_datasets["Iris Dataset"] = {
                    "file": "iris.csv",
                    "description": "–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏—Ä–∏—Å–æ–≤ (150 —Å—Ç—Ä–æ–∫, 5 –∫–æ–ª–æ–Ω–æ–∫)",
                    "target": "species"
                }

            if os.path.exists(os.path.join(test_data_path, "adult.csv")):
                available_datasets["Adult Income Dataset"] = {
                    "file": "adult.csv",
                    "description": "–î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —É—Ä–æ–≤–Ω—è –¥–æ—Ö–æ–¥–∞ (32561 —Å—Ç—Ä–æ–∫, 15 –∫–æ–ª–æ–Ω–æ–∫)",
                    "target": "income"
                }

            if not available_datasets:
                st.error("‚ùå –ì–æ—Ç–æ–≤—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ø–∞–ø–∫–µ test_data/")
                st.info("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª—ã iris.csv –∏ adult.csv –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –ø–∞–ø–∫–µ test_data/")
            else:
                selected_dataset_name = st.selectbox(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç:",
                    list(available_datasets.keys())
                )

                dataset_info = available_datasets[selected_dataset_name]

                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞—Ç–∞—Å–µ—Ç–µ
                st.info(f"‚ÑπÔ∏è {dataset_info['description']}")

                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º preview
                dataset_path = os.path.join(test_data_path, dataset_info['file'])
                df_preview = pd.read_csv(dataset_path)

                st.write("**–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫):**")
                st.dataframe(df_preview.head())

                st.write(f"**–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞:** {len(df_preview)} —Å—Ç—Ä–æ–∫, {len(df_preview.columns)} –∫–æ–ª–æ–Ω–æ–∫")

                # –ù–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
                default_name = dataset_info['file'].replace('.csv', '')
                dataset_name = st.text_input(
                    "–ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ —Å–∏—Å—Ç–µ–º–µ:",
                    value=default_name,
                    help="–ò–º—è –ø–æ–¥ –∫–æ—Ç–æ—Ä—ã–º –¥–∞—Ç–∞—Å–µ—Ç –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Å–∏—Å—Ç–µ–º–µ"
                )

                target_column = st.selectbox(
                    "–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (target):",
                    options=df_preview.columns.tolist(),
                    index=df_preview.columns.tolist().index(dataset_info['target']) if dataset_info['target'] in df_preview.columns.tolist() else 0
                )

                preprocess_categorical = st.checkbox(
                    "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö",
                    value=True,
                    help="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç –∏ –∑–∞–∫–æ–¥–∏—Ä—É–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"
                )

                make_shared = st.checkbox(
                    "üåê –°–¥–µ–ª–∞—Ç—å –æ–±—â–∏–º (–¥–æ—Å—Ç—É–ø–µ–Ω –≤—Å–µ–º)",
                    value=True,  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —à–∞–±–ª–æ–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –æ–±—â–∏–µ
                    help="–û–±—â–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –¥–æ—Å—Ç—É–ø–Ω—ã –≤—Å–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –∏ –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å —É–¥–∞–ª–µ–Ω—ã"
                )

                if st.button("üöÄ –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç", type="primary"):
                    with st.spinner(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ {selected_dataset_name}..."):
                        with open(dataset_path, 'rb') as f:
                            result = upload_dataset(
                                f,
                                target_column,
                                dataset_name,
                                preprocess_categorical,
                                make_shared
                            )

                        if result:
                            st.success(f"‚úÖ {result['message']}")
                            st.write("**–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ:**")
                            st.json(result)

                            if preprocess_categorical and result.get('message'):
                                st.info("‚ÑπÔ∏è –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –±—ã–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω—ã")

        else:  # –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–æ–π CSV
            uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ CSV —Ñ–∞–π–ª", type=["csv"])

            if uploaded_file is not None:
                # –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞
                df = pd.read_csv(uploaded_file)
                st.write("**–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫):**")
                st.dataframe(df.head())

                st.write(f"**–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞:** {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")

                # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏
                col1, col2 = st.columns(2)

                with col1:
                    dataset_name = st.text_input(
                        "–ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)",
                        placeholder="–û—Å—Ç–∞–≤—å—Ç–µ –ø—É—Å—Ç—ã–º –¥–ª—è –∞–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
                    )

                    target_column = st.selectbox(
                        "–í—ã–±–µ—Ä–∏—Ç–µ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (target):",
                        options=df.columns.tolist()
                    )

                with col2:
                    preprocess_categorical = st.checkbox(
                        "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö",
                        value=True,
                        help="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç –∏ –∑–∞–∫–æ–¥–∏—Ä—É–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"
                    )

                    make_shared = st.checkbox(
                        "üåê –°–¥–µ–ª–∞—Ç—å –æ–±—â–∏–º (–¥–æ—Å—Ç—É–ø–µ–Ω –≤—Å–µ–º)",
                        value=False,
                        help="–û–±—â–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –¥–æ—Å—Ç—É–ø–Ω—ã –≤—Å–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –∏ –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å —É–¥–∞–ª–µ–Ω—ã"
                    )

                    st.write("**–ö–æ–ª–æ–Ω–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞:**")
                    for col in df.columns:
                        dtype_icon = "üî¢" if df[col].dtype in ['int64', 'float64'] else "üìù"
                        st.text(f"{dtype_icon} {col}")

                if st.button("üöÄ –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç", type="primary"):
                    with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞..."):
                        # –°–±—Ä–æ—Å —Ñ–∞–π–ª–∞ –≤ –Ω–∞—á–∞–ª–æ
                        uploaded_file.seek(0)

                        result = upload_dataset(
                            uploaded_file,
                            target_column,
                            dataset_name if dataset_name else None,
                            preprocess_categorical,
                            make_shared
                        )

                        if result:
                            st.success(f"‚úÖ {result['message']}")
                            st.write("**–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ:**")
                            st.json(result)

                            if preprocess_categorical and result.get('message'):
                                st.info("‚ÑπÔ∏è –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –±—ã–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω—ã")

    with tab2:
        st.subheader("üìä –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã")

        if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫"):
            st.rerun()

        datasets = get_datasets()

        if not datasets:
            st.info("–ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –≤–æ –≤–∫–ª–∞–¥–∫–µ '–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç'.")
        else:
            st.write(f"**–í—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤:** {len(datasets)}")

            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            current_username = st.session_state.get("username", "unknown")

            for dataset in datasets:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–ª–∞–¥–µ–ª—å—Ü–∞
                owner = dataset.get('owner')
                display_owner = owner if owner else "–û–±—â–∏–π"
                is_owner = owner == current_username
                icon = "üìÅ" if is_owner else "üåê"

                with st.expander(f"{icon} {dataset['dataset_id']}", expanded=False):
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.metric("–°—Ç—Ä–æ–∫", dataset['rows'])
                    with col2:
                        st.metric("–ö–æ–ª–æ–Ω–æ–∫", dataset['columns'])
                    with col3:
                        st.metric("Target", dataset['target_column'])

                    st.write("**–ü—Ä–∏–∑–Ω–∞–∫–∏ (features):**")
                    st.write(", ".join(dataset['feature_columns']))

                    st.write(f"**–°–æ–∑–¥–∞–Ω:** {dataset['created_at']}")

                    # –í–ª–∞–¥–µ–ª–µ—Ü
                    if is_owner:
                        st.info(f"üë§ –í–ª–∞–¥–µ–ª–µ—Ü: **{display_owner}** (–≤—ã)")
                    elif not owner:
                        st.info(f"üë§ –í–ª–∞–¥–µ–ª–µ—Ü: **{display_owner}**")
                    else:
                        st.warning(f"üë§ –í–ª–∞–¥–µ–ª–µ—Ü: **{display_owner}**")

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —ç–Ω–∫–æ–¥–µ—Ä–æ–≤
                    has_encoders = has_feature_encoders(dataset['dataset_id'])
                    if has_encoders:
                        st.success("üîê –î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —ç–Ω–∫–æ–¥–µ—Ä—ã –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

                    # –ö–Ω–æ–ø–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º
                    st.write("")  # –û—Ç—Å—Ç—É–ø

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–Ω–æ –ª–∏ —É–¥–∞–ª–∏—Ç—å (—Ç–æ–ª—å–∫–æ –≤–ª–∞–¥–µ–ª–µ—Ü –∏–ª–∏ –Ω–µ –æ–±—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç)
                    if not owner:
                        st.info("üîí –û–±—â–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –Ω–µ–ª—å–∑—è —É–¥–∞–ª–∏—Ç—å")
                    elif not is_owner:
                        st.warning("üîí –¢–æ–ª—å–∫–æ –≤–ª–∞–¥–µ–ª–µ—Ü –º–æ–∂–µ—Ç —É–¥–∞–ª–∏—Ç—å —ç—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç")
                    else:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ–∂–∏–¥–∞–µ—Ç—Å—è –ª–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
                        confirm_key = f"confirm_delete_dataset_{dataset['dataset_id']}"
                        if st.session_state.get(confirm_key, False):
                            st.warning("‚ö†Ô∏è –í—ã —É–≤–µ—Ä–µ–Ω—ã? –≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–µ–ª—å–∑—è –æ—Ç–º–µ–Ω–∏—Ç—å!")

                            col_btn1, col_btn2 = st.columns(2)
                            with col_btn1:
                                if st.button("‚úÖ –î–∞, —É–¥–∞–ª–∏—Ç—å", key=f"confirm_yes_{dataset['dataset_id']}", type="primary"):
                                    with st.spinner(f"–£–¥–∞–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ {dataset['dataset_id']}..."):
                                        result = delete_dataset(dataset['dataset_id'])
                                        if result:
                                            st.success(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç {dataset['dataset_id']} —É–¥–∞–ª–µ–Ω")
                                            st.session_state[confirm_key] = False
                                            st.rerun()
                            with col_btn2:
                                if st.button("‚ùå –û—Ç–º–µ–Ω–∞", key=f"confirm_no_{dataset['dataset_id']}", type="secondary"):
                                    st.session_state[confirm_key] = False
                                    st.rerun()
                        else:
                            if st.button("üóëÔ∏è –£–¥–∞–ª–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç", key=f"delete_dataset_{dataset['dataset_id']}", type="secondary"):
                                st.session_state[confirm_key] = True
                                st.rerun()

elif page == "üéØ –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å":
    st.header("üéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ")

    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
    datasets = get_datasets()

    if not datasets:
        st.warning("‚ö†Ô∏è –ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤. –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –≤ —Ä–∞–∑–¥–µ–ª–µ '–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏'.")
    else:
        # –í—ã–±–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞
        dataset_names = [ds['dataset_id'] for ds in datasets]
        selected_dataset_id = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç:", dataset_names)

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞—Ç–∞—Å–µ—Ç–µ
        selected_dataset = next(ds for ds in datasets if ds['dataset_id'] == selected_dataset_id)

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        num_features = len(selected_dataset['feature_columns'])

        with st.expander("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ", expanded=True):
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("–°—Ç—Ä–æ–∫", selected_dataset['rows'])
            with col2:
                st.metric("–ö–æ–ª–æ–Ω–æ–∫", selected_dataset['columns'])
            with col3:
                st.metric("–ü—Ä–∏–∑–Ω–∞–∫–æ–≤", num_features)
            with col4:
                st.metric("Target", selected_dataset['target_column'])

            st.write("**–ü—Ä–∏–∑–Ω–∞–∫–∏ (features):**")
            st.write(", ".join(selected_dataset['feature_columns']))

        # –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–∏–ø—ã –º–æ–¥–µ–ª–µ–π
        available_models = get_available_models()

        if not available_models:
            st.warning("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–∏–ø–æ–≤ –º–æ–¥–µ–ª–µ–π")
        else:
            # –í—ã–±–æ—Ä —Ç–∏–ø–∞ –º–æ–¥–µ–ª–∏
            model_names = [m["name"] for m in available_models]
            selected_model_type = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –º–æ–¥–µ–ª–∏:", model_names, key="dataset_model_select")

            # –ù–∞—Ö–æ–¥–∏–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            selected_model = next(m for m in available_models if m["name"] == selected_model_type)

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
            with st.expander("‚ÑπÔ∏è –û–ø–∏—Å–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"):
                st.write(selected_model["description"])

            # –ò–º—è –º–æ–¥–µ–ª–∏
            model_name = st.text_input(
                "–í–≤–µ–¥–∏—Ç–µ –∏–º—è –¥–ª—è –º–æ–¥–µ–ª–∏:",
                value=f"model_{selected_dataset_id}"
            )

            # –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            st.subheader("‚öôÔ∏è –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã")

            hyperparameters = {}
            default_hyperparams = selected_model["default_hyperparameters"]

            cols = st.columns(2)

            for idx, (key, default_value) in enumerate(default_hyperparams.items()):
                col = cols[idx % 2]

                with col:
                    if isinstance(default_value, int):
                        if key == "random_state":
                            hyperparameters[key] = st.number_input(
                                key, value=default_value, min_value=0, max_value=9999, key=f"dataset_{key}"
                            )
                        else:
                            hyperparameters[key] = st.number_input(
                                key, value=default_value, min_value=1, key=f"dataset_{key}"
                            )
                    elif isinstance(default_value, float):
                        hyperparameters[key] = st.number_input(
                            key, value=default_value, min_value=0.0, format="%.4f", key=f"dataset_{key}"
                        )
                    elif isinstance(default_value, str):
                        hyperparameters[key] = st.text_input(key, value=default_value, key=f"dataset_{key}")
                    elif default_value is None:
                        use_none = st.checkbox(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å None –¥–ª—è {key}", value=True, key=f"dataset_none_{key}")
                        if not use_none:
                            hyperparameters[key] = st.number_input(f"{key} (–∑–Ω–∞—á–µ–Ω–∏–µ)", value=10, key=f"dataset_val_{key}")
                        else:
                            hyperparameters[key] = None

            # –ö–Ω–æ–ø–∫–∞ –æ–±—É—á–µ–Ω–∏—è
            if st.button("üöÄ –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ", type="primary"):
                with st.spinner("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏..."):
                    result = train_model_from_dataset(
                        selected_model_type,
                        model_name,
                        selected_dataset_id,
                        hyperparameters
                    )

                    if result:
                        st.success(f"‚úÖ {result['message']}")
                        st.write("**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è:**")

                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("ID –º–æ–¥–µ–ª–∏", result['model_id'])
                        with col2:
                            st.metric("–¢–∏–ø –º–æ–¥–µ–ª–∏", result['model_type'])

                        if result.get('metrics'):
                            st.write("**–ú–µ—Ç—Ä–∏–∫–∏:**")
                            st.json(result['metrics'])


elif page == "üîÆ –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ":
    st.header("üîÆ –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")

    # –ü–æ–ª—É—á–∞–µ–º –æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
    trained_models = get_trained_models()

    if not trained_models:
        st.warning("–ù–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å.")
    else:
        # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
        model_ids = [m["model_id"] for m in trained_models]
        selected_model_id = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:", model_ids)

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
        selected_model_info = next(m for m in trained_models if m["model_id"] == selected_model_id)

        with st.expander("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏", expanded=True):
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –º–µ—Ç—Ä–∏–∫–∞–º–∏
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("–¢–∏–ø –º–æ–¥–µ–ª–∏", selected_model_info.get('model_type', 'N/A'))
            with col2:
                st.metric("–°—Ç–∞—Ç—É—Å", "–û–±—É—á–µ–Ω–∞ ‚úì" if selected_model_info.get('is_trained') else "–ù–µ –æ–±—É—á–µ–Ω–∞")
            with col3:
                n_features = selected_model_info.get('n_features', 'N/A')
                st.metric("–ü—Ä–∏–∑–Ω–∞–∫–æ–≤", n_features)

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            st.write("**–ü–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:**")
            st.json(selected_model_info)

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–∞–∂–Ω–æ–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        n_features = selected_model_info.get('n_features', None)
        if n_features:
            st.warning(f"""
            ‚ö†Ô∏è **–í–∞–∂–Ω–æ:** –≠—Ç–∞ –º–æ–¥–µ–ª—å –æ–∂–∏–¥–∞–µ—Ç **{n_features} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤** –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è. 
            –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç–µ –∏–º–µ–Ω–Ω–æ —Å—Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–µ–Ω–∏–π.
            """)
        else:
            st.info("""
            ‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. 
            –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ç–µ–º, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –º–æ–¥–µ–ª—å –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞.
            """)


        # –î–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        st.subheader("üìä –î–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")

        # –í—ã–±–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è —ç–Ω–∫–æ–¥–µ—Ä–æ–≤ (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏)
        datasets = get_datasets()
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –¥–∞—Ç–∞—Å–µ—Ç—ã —Å —ç–Ω–∫–æ–¥–µ—Ä–∞–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–Ω–µ —Ç–æ–ª—å–∫–æ target)
        datasets_with_encoders = [d for d in datasets if has_feature_encoders(d["dataset_id"])]

        if datasets_with_encoders:
            dataset_options = ["–ë–µ–∑ —ç–Ω–∫–æ–¥–∏–Ω–≥–∞ (—á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ)"] + [d["dataset_id"] for d in datasets_with_encoders]
            selected_dataset = st.selectbox(
                "–î–∞—Ç–∞—Å–µ—Ç –¥–ª—è —ç–Ω–∫–æ–¥–µ—Ä–æ–≤ (–≤—ã–±–µ—Ä–∏—Ç–µ, –µ—Å–ª–∏ –µ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏):",
                dataset_options,
                help="–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ–±—É—á–∞–ª–∞—Å—å –º–æ–¥–µ–ª—å, –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
            )
        else:
            st.info("‚ÑπÔ∏è –ù–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ–∂–∏–º –±–µ–∑ —ç–Ω–∫–æ–¥–∏–Ω–≥–∞.")
            selected_dataset = "–ë–µ–∑ —ç–Ω–∫–æ–¥–∏–Ω–≥–∞ (—á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ)"

        use_encoding = selected_dataset != "–ë–µ–∑ —ç–Ω–∫–æ–¥–∏–Ω–≥–∞ (—á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ)"

        uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏", type="csv", key="pred_csv")

        pred_features = None
        num_features_uploaded = 0
        features_match = True
        uploaded_csv_bytes = None

        if uploaded_file:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–∞ —Å–µ—Ä–≤–µ—Ä
            uploaded_csv_bytes = uploaded_file.getvalue()

            df = pd.read_csv(uploaded_file)
            st.write("**–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫):**")
            st.dataframe(df.head())

            # –£–±–∏—Ä–∞–µ–º target –∫–æ–ª–æ–Ω–∫—É –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
            feature_columns = [col for col in df.columns if col.lower() not in ['target', 'label', 'class', 'species', 'income']]

            if len(feature_columns) < len(df.columns):
                st.info(f"‚ÑπÔ∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∏ —É–¥–∞–ª–µ–Ω–∞ —Ü–µ–ª–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è {len(feature_columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.")
                df = df[feature_columns]

            num_features_uploaded = len(feature_columns)
            pred_features = df.values.tolist()
            st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(pred_features)} –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            if use_encoding and selected_dataset:
                # –î–ª—è —Ä–µ–∂–∏–º–∞ —Å —ç–Ω–∫–æ–¥–∏–Ω–≥–æ–º –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—É
                dataset_info = get_dataset_info(selected_dataset)
                if dataset_info:
                    expected_features = dataset_info['feature_columns']
                    expected_count = len(expected_features)
                    if num_features_uploaded != expected_count:
                        features_match = False
                        st.error(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –î–∞—Ç–∞—Å–µ—Ç '{selected_dataset}' –æ–∂–∏–¥–∞–µ—Ç {expected_count} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∞ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {num_features_uploaded}!")
                        st.info(f"üìã –û–∂–∏–¥–∞–µ–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(expected_features[:5])}{'...' if len(expected_features) > 5 else ''}")
            elif not use_encoding and selected_model_info.get("n_features") is not None:
                # –î–ª—è —Ä–µ–∂–∏–º–∞ –±–µ–∑ —ç–Ω–∫–æ–¥–∏–Ω–≥–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–æ–¥–µ–ª–∏
                if num_features_uploaded != selected_model_info["n_features"]:
                    features_match = False
                    st.error(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ú–æ–¥–µ–ª—å –æ–∂–∏–¥–∞–µ—Ç {selected_model_info['n_features']} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∞ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {num_features_uploaded}!")

        # –ö–Ω–æ–ø–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º —Ü–≤–µ—Ç–æ–º
        if not pred_features:
            st.warning("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
        elif not features_match:
            # –ö—Ä–∞—Å–Ω–∞—è –∫–Ω–æ–ø–∫–∞ (secondary) –ø—Ä–∏ –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            if st.button("‚ö†Ô∏è –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (–Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤!)", type="secondary"):
                if use_encoding:
                    st.error("‚ùå –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º!")
                else:
                    st.error("‚ùå –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –º–æ–¥–µ–ª—å—é!")
        else:
            # –°–∏–Ω—è—è –∫–Ω–æ–ø–∫–∞ (primary) –ø—Ä–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            if st.button("üîÆ –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ", type="primary"):
                if pred_features:
                    with st.spinner("–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π..."):
                        if use_encoding:
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
                            import io
                            csv_file = io.BytesIO(uploaded_csv_bytes)
                            result = predict_from_csv(selected_model_id, selected_dataset, csv_file)
                        else:
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                            result = predict(selected_model_id, pred_features)

                    if result:
                        st.success("‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ–ª—É—á–µ–Ω—ã")

                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                        results_df = pd.DataFrame(
                            {
                                "Sample": range(1, len(result["predictions"]) + 1),
                                "Prediction": result["predictions"],
                            }
                        )

                        if result.get("probabilities"):
                            for i, probs in enumerate(result["probabilities"]):
                                for j, prob in enumerate(probs):
                                    results_df[f"Class_{j}_Prob"] = [
                                        p[j] for p in result["probabilities"]
                                    ]

                        st.dataframe(results_df)

                        st.json(result)
                else:
                    st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")


else:  # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏
    st.header("üìã –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏")

    # –ü–æ–ª—É—á–∞–µ–º –æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
    trained_models = get_trained_models()

    if not trained_models:
        st.info("–ù–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
    else:
        st.subheader(f"–í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π: {len(trained_models)}")

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ –ø–æ –≤–ª–∞–¥–µ–ª—å—Ü—É
        current_username = st.session_state.get("username", "unknown")
        my_models = [m for m in trained_models if m.get("owner") == current_username]
        other_models = [m for m in trained_models if m.get("owner") != current_username]

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–≤–æ–∏ –º–æ–¥–µ–ª–∏
        if my_models:
            st.write(f"**üë§ –í–∞—à–∏ –º–æ–¥–µ–ª–∏ ({len(my_models)}):**")
            for model in my_models:
                owner = model.get('owner')
                display_owner = owner if owner else "–û–±—â–∏–π"

                with st.expander(f"üéØ {model['model_id']}", expanded=False):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("–¢–∏–ø", model.get('model_type', 'N/A'))
                    with col2:
                        st.metric("–°—Ç–∞—Ç—É—Å", "‚úÖ –û–±—É—á–µ–Ω–∞" if model.get('is_trained') else "‚ùå –ù–µ –æ–±—É—á–µ–Ω–∞")
                    with col3:
                        st.metric("–ü—Ä–∏–∑–Ω–∞–∫–æ–≤", model.get('n_features', 'N/A'))

                    st.info(f"üë§ –í–ª–∞–¥–µ–ª–µ—Ü: **{display_owner}** (–≤—ã)")
                    st.write(f"üìÖ –°–æ–∑–¥–∞–Ω–∞: {model.get('created_at', 'N/A')}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—É–∂–∏–µ –º–æ–¥–µ–ª–∏
        if other_models:
            st.write(f"**üë• –ú–æ–¥–µ–ª–∏ –¥—Ä—É–≥–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π ({len(other_models)}):**")
            for model in other_models:
                owner = model.get('owner')
                display_owner = owner if owner else "–û–±—â–∏–π"

                with st.expander(f"üåê {model['model_id']}", expanded=False):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("–¢–∏–ø", model.get('model_type', 'N/A'))
                    with col2:
                        st.metric("–°—Ç–∞—Ç—É—Å", "‚úÖ –û–±—É—á–µ–Ω–∞" if model.get('is_trained') else "‚ùå –ù–µ –æ–±—É—á–µ–Ω–∞")
                    with col3:
                        st.metric("–ü—Ä–∏–∑–Ω–∞–∫–æ–≤", model.get('n_features', 'N/A'))

                    if owner:
                        st.warning(f"üë§ –í–ª–∞–¥–µ–ª–µ—Ü: **{display_owner}**")
                    else:
                        st.info(f"üë§ –í–ª–∞–¥–µ–ª–µ—Ü: **{display_owner}**")
                    st.write(f"üìÖ –°–æ–∑–¥–∞–Ω–∞: {model.get('created_at', 'N/A')}")

        # –£–¥–∞–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        st.divider()
        st.subheader("üóëÔ∏è –£–¥–∞–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")

        model_ids = [m["model_id"] for m in trained_models]
        model_to_delete = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è:", model_ids, key="delete")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–ª–∞–¥–µ–ª—å—Ü–∞
        selected_model = next((m for m in trained_models if m["model_id"] == model_to_delete), None)
        model_owner = selected_model.get("owner") if selected_model else None
        is_owner = model_owner == current_username

        col1, col2 = st.columns([1, 4])

        with col1:
            if st.button("üóëÔ∏è –£–¥–∞–ª–∏—Ç—å", type="secondary"):
                if not model_owner:
                    st.error("‚ùå –û–±—â–∏–µ –º–æ–¥–µ–ª–∏ –Ω–µ–ª—å–∑—è —É–¥–∞–ª–∏—Ç—å")
                elif not is_owner:
                    st.warning("‚ö†Ô∏è –í—ã –Ω–µ —è–≤–ª—è–µ—Ç–µ—Å—å –≤–ª–∞–¥–µ–ª—å—Ü–µ–º —ç—Ç–æ–π –º–æ–¥–µ–ª–∏")
                else:
                    with st.spinner(f"–£–¥–∞–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ '{model_to_delete}'..."):
                        result = delete_model(model_to_delete)

                    if result:
                        st.success(f"‚úÖ {result['message']}")
                        st.rerun()


# Footer
st.divider()
st.markdown("---")
st.markdown("**ML API Service Dashboard** | Built with Streamlit")
