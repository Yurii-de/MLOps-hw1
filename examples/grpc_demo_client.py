"""
–ü—Ä–æ—Å—Ç–æ–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã —Å gRPC API.

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏:
1. Health Check
2. –°–ø–∏—Å–æ–∫ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ
4. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- gRPC —Å–µ—Ä–≤–µ—Ä –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–ø—É—â–µ–Ω (python src/api/grpc_server.py)
- –î–∞—Ç–∞—Å–µ—Ç 'iris' –¥–æ–ª–∂–µ–Ω —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å (python examples/recreate_shared_datasets.py)
"""

import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
BASE_DIR = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(BASE_DIR))

import grpc

try:
    from src.proto import ml_service_pb2, ml_service_pb2_grpc
except ImportError:
    print("‚ùå ERROR: Proto files not generated!")
    print("Run: python generate_proto.py")
    exit(1)


def get_auth_token(stub):
    """
    –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ JWT —Ç–æ–∫–µ–Ω–∞.
    
    Args:
        stub: gRPC stub
        
    Returns:
        str: JWT —Ç–æ–∫–µ–Ω
    """
    print("üîê Authenticating...")
    login_request = ml_service_pb2.LoginRequest(
        username="admin",
        password="admin"
    )

    try:
        response = stub.Login(login_request)
        print("‚úÖ Authenticated as: admin")
        print(f"üé´ Token type: {response.token_type}")
        return response.access_token
    except grpc.RpcError as e:
        print(f"‚ùå Authentication failed: {e.details()}")
        exit(1)


def main():
    """–ó–∞–ø—É—Å–∫ –ø—Ä–∏–º–µ—Ä–æ–≤ gRPC API."""
    print("=" * 70)
    print("gRPC ML Service - Demo Client")
    print("=" * 70)
    print()

    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —Å–µ—Ä–≤–µ—Ä—É
    print("üì° Connecting to gRPC server at localhost:50051...")
    channel = grpc.insecure_channel("localhost:50051")
    stub = ml_service_pb2_grpc.MLServiceStub(channel)

    # –ü–æ–ª—É—á–µ–Ω–∏–µ JWT —Ç–æ–∫–µ–Ω–∞
    token = get_auth_token(stub)

    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å —Ç–æ–∫–µ–Ω–æ–º –¥–ª—è –∑–∞—â–∏—â–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    metadata = [('authorization', f'Bearer {token}')]

    try:
        # =====================================================================
        # 1. Health Check (–±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏)
        # =====================================================================
        print("\n" + "‚îÄ" * 70)
        print("1Ô∏è‚É£  HEALTH CHECK")
        print("‚îÄ" * 70)

        response = stub.HealthCheck(ml_service_pb2.Empty())
        print(f"‚úÖ Status: {response.status}")
        print(f"üì¶ Version: {response.version}")
        print(f"üéØ Models count: {response.models_count}")

        # =====================================================================
        # 2. –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–∏–ø–æ–≤ –º–æ–¥–µ–ª–µ–π
        # =====================================================================
        print("\n" + "‚îÄ" * 70)
        print("2Ô∏è‚É£  AVAILABLE MODEL TYPES")
        print("‚îÄ" * 70)

        response = stub.ListAvailableModels(ml_service_pb2.Empty(), metadata=metadata)
        for model in response.models:
            print(f"\nüìä {model.name}")
            print(f"   Description: {model.description}")
            print(f"   Hyperparameters: {dict(model.default_hyperparameters)}")

        # =====================================================================
        # 3. –°–ø–∏—Å–æ–∫ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
        # =====================================================================
        print("\n" + "‚îÄ" * 70)
        print("3Ô∏è‚É£  DATASETS")
        print("‚îÄ" * 70)

        response = stub.ListDatasets(ml_service_pb2.Empty(), metadata=metadata)
        if not response.datasets:
            print("‚ö†Ô∏è  No datasets found!")
            print("   Run: python recreate_shared_datasets.py")
            return

        for dataset in response.datasets:
            print(f"\nüìÅ {dataset.dataset_id}")
            print(f"   Rows: {dataset.rows}, Columns: {dataset.columns}")
            print(f"   Target: {dataset.target_column}")
            print(f"   Features: {', '.join(dataset.feature_columns[:3])}{'...' if len(dataset.feature_columns) > 3 else ''}")

        # =====================================================================
        # 4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ
        # =====================================================================
        print("\n" + "‚îÄ" * 70)
        print("4Ô∏è‚É£  TRAIN MODEL FROM DATASET")
        print("‚îÄ" * 70)

        print("üöÄ Training RandomForest on 'iris' dataset...")

        response = stub.TrainModelFromDataset(
            ml_service_pb2.TrainFromDatasetRequest(
                model_type="RandomForest",
                model_name="grpc_demo_model",
                dataset_id="iris",
                hyperparameters={
                    "n_estimators": "50",
                    "max_depth": "5",
                    "random_state": "42"
                }
            ),
            metadata=metadata
        )

        print(f"‚úÖ {response.message}")
        print("üìà Metrics:")
        for key, value in response.metrics.items():
            print(f"   {key}: {value:.4f}")

        # =====================================================================
        # 5. –°–ø–∏—Å–æ–∫ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        # =====================================================================
        print("\n" + "‚îÄ" * 70)
        print("5Ô∏è‚É£  TRAINED MODELS")
        print("‚îÄ" * 70)

        response = stub.ListTrainedModels(ml_service_pb2.Empty(), metadata=metadata)
        for model in response.models:
            print(f"\nüéØ {model.model_id}")
            print(f"   Type: {model.model_type}")
            print(f"   Created: {model.created_at}")

        # =====================================================================
        # 6. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (–ø—Ä–∏–º–µ—Ä —Å Iris)
        # =====================================================================
        print("\n" + "‚îÄ" * 70)
        print("6Ô∏è‚É£  PREDICTION")
        print("‚îÄ" * 70)

        # Iris sample: sepal_length, sepal_width, petal_length, petal_width
        sample = [5.1, 3.5, 1.4, 0.2]  # Should predict class 0 (setosa)
        print(f"üîç Input features: {sample}")

        response = stub.Predict(
            ml_service_pb2.PredictRequest(
                model_id="grpc_demo_model",
                features=[ml_service_pb2.FloatArray(values=sample)]
            ),
            metadata=metadata
        )

        print(f"üìä Prediction: {response.predictions[0]}")

        if response.probabilities:
            probs = response.probabilities[0].values
            print("üìà Probabilities:")
            for i, prob in enumerate(probs):
                print(f"   Class {i}: {prob:.4f}")

        # =====================================================================
        # 7. –£–¥–∞–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (cleanup)
        # =====================================================================
        print("\n" + "‚îÄ" * 70)
        print("7Ô∏è‚É£  CLEANUP (Delete demo model)")
        print("‚îÄ" * 70)

        response = stub.DeleteModel(
            ml_service_pb2.DeleteRequest(model_id="grpc_demo_model"),
            metadata=metadata
        )
        print(f"‚úÖ {response.message}")

    except grpc.RpcError as e:
        print(f"\n‚ùå gRPC Error: {e.code()}")
        print(f"   Details: {e.details()}")
        print("\nüí° Make sure the gRPC server is running:")
        print("   python src/api/grpc_server.py")

    except Exception as e:
        print(f"\n‚ùå Error: {e}")

    finally:
        channel.close()

    print("\n" + "=" * 70)
    print("‚úÖ Demo completed!")
    print("=" * 70)


if __name__ == "__main__":
    main()
